# ğŸ“‚ Data Folder

This folder is the landing zone for the **Instacart Online Grocery Dataset** (used in this project).  
The raw files are too large to upload to GitHub, but you can download them yourself from Kaggle or other sources.

---

## ğŸ“Š Dataset Used

**Instacart Online Grocery Shopping Dataset (2017, Kaggle)**  
- Orders: `orders.csv`
- Aisles: `aisles.csv`
- Departments: `departments.csv`
- Order details (prior): `order_products__prior.csv`
- Order details (train): `order_products__train.csv`
- Products: `products.csv`

ğŸ“¥ Download from Kaggle:  
ğŸ‘‰ https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset?select=orders.csv

---

## ğŸ“‚ Folder Structure (Medallion)

After download, place files under the following paths in your **Azure Data Lake (ADLS Gen2)** or local project structure:

---
```text
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ online_retail_ii/
â”‚       â””â”€â”€ landing_date=YYYY-MM-DD/
â”‚           â”œâ”€â”€ orders.csv
â”‚           â”œâ”€â”€ aisles.csv
â”‚           â”œâ”€â”€ departments.csv
â”‚           â”œâ”€â”€ order_products__prior.csv
â”‚           â”œâ”€â”€ order_products__train.csv
â”‚           â””â”€â”€ products.csv
â”œâ”€â”€ bronze/ <- created by Synapse Spark (Parquet)
â”œâ”€â”€ silver/ <- curated fact/dim tables
â””â”€â”€ gold/ <- ML features + predictions
```
---
- **raw/** â†’ Original CSVs (as downloaded).  
- **bronze/** â†’ Standardized Parquet with metadata (`ingest_ts`, `ingest_date`).  
- **silver/** â†’ Clean curated tables (dim_products, dim_orders, fact_order_products).  
- **gold/** â†’ Features and ML prediction outputs.  

---

## âš¡ How to Ingest into Azure

1. Upload raw CSVs to your ADLS Gen2 `data` container in the path above.  
   - Example:  
     `abfss://data@<your_storage>.dfs.core.windows.net/raw/online_retail_ii/landing_date=2025-08-24/orders.csv`

2. Run the **Bronze ETL notebook** â†’ writes to `bronze/`.  
3. Run the **Silver ETL notebook** â†’ writes to `silver/`.  
4. Run the **Gold ETL notebook** â†’ writes to `gold/`.  

---

## ğŸ“ Notes

- Files are **not checked into GitHub** due to size limits.  
- Please download them separately and place them under `data/raw/...` before running notebooks.  
- Kaggle account required to download the dataset.  
